{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9eb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Group-Created Zillow Functions\n",
    "import wrangle\n",
    "\n",
    "# Block Warning Boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccf9f3",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>\n",
    "\n",
    "\n",
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85003cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>squarefeet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>regionidzip</th>\n",
       "      <th>fips</th>\n",
       "      <th>logerror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>96978.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>1023282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>97099.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>464000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>97078.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>564778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>96330.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>145143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>96293.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>773303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  squarefeet  year_built  regionidzip    fips   logerror\n",
       "0       4.0        3.5      3100.0      1998.0      96978.0  6059.0  1023282.0\n",
       "1       2.0        1.0      1465.0      1967.0      97099.0  6111.0   464000.0\n",
       "2       3.0        2.0      1243.0      1962.0      97078.0  6059.0   564778.0\n",
       "3       4.0        3.0      2376.0      1970.0      96330.0  6037.0   145143.0\n",
       "4       4.0        3.0      2962.0      1950.0      96293.0  6037.0   773303.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle.get_zillow_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2af7f0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tax_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tax_value'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-289e1b2f19ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using the functions from my compiled wrangle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrangle_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMin_Max_Scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codeup_Data_Science/Zillow-Clusterfication/Individual Works/wrangle.py\u001b[0m in \u001b[0;36mwrangle_zillow\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m'''Acquire and prepare data from Zillow database for explore'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# Acquire and Prep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mzillow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_zillow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codeup_Data_Science/Zillow-Clusterfication/Individual Works/wrangle.py\u001b[0m in \u001b[0;36mprepare_zillow\u001b[0;34m(zillow)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Remove extreme outliers (there will still be a few, but our data should be less skewed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mzillow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzillow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bedrooms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bathrooms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'squarefeet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tax_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Feature Engineering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codeup_Data_Science/Zillow-Clusterfication/Individual Works/wrangle.py\u001b[0m in \u001b[0;36mremove_outliers\u001b[0;34m(df, k, col_list)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get quartiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0miqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq1\u001b[0m   \u001b[0;31m# calculate interquartile range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tax_value'"
     ]
    }
   ],
   "source": [
    "# Using the functions from my compiled wrangle file\n",
    "train, validate, test = wrangle.wrangle_zillow()\n",
    "train, validate, test = wrangle.Min_Max_Scaler(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbbd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at correlations with my target variable\n",
    "train.corr()['tax_value'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d33677",
   "metadata": {},
   "source": [
    "It looks like my top 3 are \n",
    "1. squarefeet\n",
    "2. bathrooms\n",
    "3. year_built / years_old\n",
    "\n",
    "Considering that correlations are more for continuous variables, I can really only accept squarefeet from this list at the moment. You could almost consider bathrooms and year_built/years_old as categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb07229",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train, corner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function, arguments are dataframe and two lists of columns.\n",
    "def plot_categorical_and_continuous_vars(df, continuous, categorical):\n",
    "    '''\n",
    "    Takes in a dataframe, a list of continuous variables, and a list of categorical \n",
    "    variables of the dataframe as arguments. Creates three different plots of each\n",
    "    categorical pair.\n",
    "    '''\n",
    "    # loop through each column in the first list\n",
    "    for con in continuous:\n",
    "        # loop through each column in the second list, creating a loop for each categorical pair\n",
    "        for cat in categorical:\n",
    "            # each loop returns three subplots in a figure. Plots a swarmplot, stripplot, and boxplot.\n",
    "            plt.figure(figsize = (20,10))\n",
    "            plt.subplot(1,3,1)\n",
    "            sns.swarmplot(x=df[cat], y=df[con], data=df)\n",
    "            plt.subplot(1,3,2)\n",
    "            sns.stripplot(x=df[cat], y=df[con], data=df)\n",
    "            plt.subplot(1,3,3)\n",
    "            sns.boxplot(x=df[cat], y=df[con], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['tax_value','squarefeet']\n",
    "categorical= ['bedrooms','bathrooms','years_old','regionidzip']\n",
    "train.sample(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fff9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOn't run this until finished\n",
    "#plot_categorical_and_continuous_vars(train.sample(10_000),continuous,categorical )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff3fa0",
   "metadata": {},
   "source": [
    "### Let's do some statistical questions.  \n",
    "#### 1. Are homes with more bedrooms worth more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting my confidence level to 95%\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create some array's for this question\n",
    "tax_value_2Bd = train[train.bedrooms == 2].tax_value\n",
    "tax_value_5Bd = train[train.bedrooms == 5].tax_value\n",
    "\n",
    "# Check to see if my variances are equal; (they are not)\n",
    "# tax_value_2Bd.var() , tax_value_5Bd.var()\n",
    "\n",
    "# Define my hypothesis before testing:\n",
    "# H0: There is no difference in tax_value between homes with 2 bedrooms vs homes with 5 bedrooms.\n",
    "# Ha: There is a difference in tax_value between homes with 2 bedrooms vs homes with 5 bedrooms.\n",
    "\n",
    "# This is a two-sampled, two-tailed test. \n",
    "t, p = stats.ttest_ind(tax_value_2Bd, tax_value_5Bd, equal_var=False)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01cf082",
   "metadata": {},
   "source": [
    "It didn't seem like there was much difference between home value bedrooms in the charts above, but my Two-Tailed T-Test proved otherwise. It seems more bedrooms does mean more value, which seems intuitive, but it's always good to check and see if your data agrees with you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b1045",
   "metadata": {},
   "source": [
    "#### 2. Are younger homes higher in tax_value than old homes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96301061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the arrays i want for my t-test\n",
    "older_homes = train[train.years_old >= train.years_old.mean()].tax_value\n",
    "younger_homes = train[train.years_old < train.years_old.mean()].tax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9249304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define my hypothesis before testing:\n",
    "# H0: Homes older than the average cost more or the same as homes younger than the average\n",
    "# Ha: Homes older than the average cost less than homes younger than the average\n",
    "\n",
    "# use stats.ttest to calculate t and p\n",
    "t, p = stats.ttest_ind(older_homes, younger_homes, equal_var=False)\n",
    "\n",
    "if p/2 < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd55185",
   "metadata": {},
   "source": [
    "As we expected, the data shows that new homes have higher tax_value than older homes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49a4a7",
   "metadata": {},
   "source": [
    "#### 3. Are homes with more bathrooms worth more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f46a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bathrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95834033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create some array's for this question\n",
    "tax_value_1Bth = train[train.bathrooms == 1].tax_value\n",
    "tax_value_4Bth = train[train.bathrooms == 4].tax_value\n",
    "\n",
    "# Check to see if my variances are equal; (they are not)\n",
    "# tax_value_2Bd.var() , tax_value_5Bd.var()\n",
    "\n",
    "# Define my hypothesis before testing:\n",
    "# H0: There is no difference in tax_value between homes with 2 bedrooms vs homes with 5 bedrooms.\n",
    "# Ha: There is a difference in tax_value between homes with 2 bedrooms vs homes with 5 bedrooms.\n",
    "\n",
    "# This is a two-sampled, two-tailed test. \n",
    "t, p = stats.ttest_ind(tax_value_2Bd, tax_value_5Bd, equal_var=False)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8466f",
   "metadata": {},
   "source": [
    "1. Why do some properties have a much higher value than others when they are located so close to each other?\n",
    "2. Are houses with a high bedroom count but a low bathroom count, less valueable?\n",
    "3. Are houses of a certain year built more valuable than others?\n",
    "4. Are there certain countys that are harder to predict taxvaluedollarcnt for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447da89",
   "metadata": {},
   "source": [
    "I wanna see what my most valuable features are according to these feature selection models. To get started, I'll need to split my data and use the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling my data\n",
    "# Then assigning my features to X, and target variable to y, for train dataframe\n",
    "train, validate, test = wrangle.wrangle_zillow()\n",
    "X_train = train.drop(columns=['tax_value'])\n",
    "y_train = train.tax_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dabf2b",
   "metadata": {},
   "source": [
    "# Select Kbest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Parameters: f_regression stats test, give me 2 features\n",
    "f_selector = SelectKBest(f_regression, k=2)\n",
    "\n",
    "# Find the top 2 X's correlated with y\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "# Boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()\n",
    "\n",
    "# Get list of top K features. \n",
    "f_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "print(\"KBest Top Two Features:\", f_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0c225",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# initialize the ML algorithm\n",
    "lm = LinearRegression()\n",
    "\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(lm, 2)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train,y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train.iloc[:,feature_mask].columns.tolist()\n",
    "\n",
    "print(\"Recursive Feature Elimination Top Two Features:\",rfe_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view list of columns and their ranking\n",
    "\n",
    "# get the ranks\n",
    "var_ranks = rfe.ranking_\n",
    "# get the variable names\n",
    "var_names = X_train.columns.tolist()\n",
    "# combine ranks and names into a df for clean viewing\n",
    "rfe_ranks_df = pd.DataFrame({'Var': var_names, 'Rank': var_ranks})\n",
    "# sort the df by rank\n",
    "rfe_ranks_df.sort_values('Rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad535b02",
   "metadata": {},
   "source": [
    "Alright, so two different models put bathrooms at the top of the list (Kbest comes in reverse order). With this, I will assume my top three features to be Bathrooms, Bedrooms, and Squarefeet. I'll explore these further with some statistical tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22411392",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aba1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['bedrooms', 'bathrooms', 'total_living_area']\n",
    "for col in col_list:\n",
    "    sns.lmplot(x=col, y=\"tax_value\", data=train, line_kws={'color': 'red'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d865d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa7be86",
   "metadata": {},
   "source": [
    "<span style=\"color: red\">\n",
    "\n",
    "  \n",
    "# Explore (.ipynb) - Ask clear question, [discover], provide a clear answer\n",
    "At least 4 of the questions asked and answered of the data are shared in the final report notebook. You should call out questions of the data using natural language that speaks to the business stakeholders in markdown cells, ideally a header prior to the visualization or statistical test, that you then explore. This does not take the place of stating your null hypothesis/alternative hypothesis when doing a statistical test. But those hypotheses are generally for you. By writing questions that you intend to answer with visualizations and statistical tests in natural language, like \"Are office supplies leading to differences in profit in Texas?\", you are able to guide both yourself and your reader through the highlights of your analysis. You ask a question, create a visual, run a statistical test (if appropriate), and wrap it nicely with a markdown cell that contains a clear answer in layman's terms. You do all that before moving to the next question.\n",
    "\n",
    "# Explore (.ipynb) - Exploring though visualizations\n",
    "At least 5 visualizations are included in your final report. The ones included answer a question (remember, NO is an answer) and the one(s) to provide necessary context (such as the distribution of the target variable). All statistical tests included in the final report should be supported with an visualization of the interaction of the variables being tested. Charts in the final report should have titles and labels that are descriptive and useful for the end user/audience/consumer of the report. All visualizations in the final report are mentioned or discussed if a verbal presentation is given.\n",
    "\n",
    "# Explore (.ipynb) - Statistical tests\n",
    "At least 2 statistical tests are included in your final report. The correct tests are run, given the data type and distribution, and the correct conclusions are drawn. - correlation: 2 continuous variables, normally distributed, testing for LINEAR correlation only (H_0: Not linearly dependent) - independent t-test: 1 continuous, somewhat normally distributed variable, one boolean variable, equal variance, independent (H_0: population mean of each group is equal) - chi-square test: 2 discrete variables. (H_0: the 2 variables are independent of each other). (other tests may be used)\n",
    "    \n",
    "# Explore (.ipynb) - Summary\n",
    "Following your exploration section, you summarize your analysis (in a markdown cell using natural language): what you found and how you will use it moving forward. This includes key takeaways from all the questions answered in explore, a list of which features will be used in modeling and why, and which features will not move forward and why. You may only call out a few of these features in the presentation, but having that there for reference is important in a report. A group of features may have the same reason why, and those can be mentioned together.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77170b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
